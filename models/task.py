# -*- coding: utf-8 -*-
import anthropic
import logging
import time
import re
from odoo import models, fields, api
from odoo.exceptions import ValidationError, UserError
from datetime import date

_logger = logging.getLogger(__name__)


class TaskManagerTask(models.Model):
    _name = 'task.manager.task'
    _description = 'Task Manager - Task'
    _inherit = ['mail.thread', 'mail.activity.mixin']
    _order = 'priority desc, deadline asc, id desc'

    # ========== CHAMPS DE BASE ==========
    
    name = fields.Char(
        string='Titre de la t√¢che',
        required=True,
        tracking=True,
        index=True,
        help="Titre court et descriptif de la t√¢che"
    )
    
    description = fields.Text(
        string='Description',
        tracking=True,
        help="Description d√©taill√©e de la t√¢che"
    )
    
    # ========== CHAMPS DE PRIORIT√â ET √âTAT ==========
    
    priority = fields.Selection([
        ('low', 'Faible'),
        ('medium', 'Moyenne'),
        ('high', 'Haute')
    ], string='Priorit√©', default='medium', required=True, tracking=True)
    
    state = fields.Selection([
        ('new', 'Nouveau'),
        ('in_progress', 'En cours'),
        ('done', 'Termin√©')
    ], string='√âtat', default='new', required=True, tracking=True)
    
    # ========== CHAMPS DE TEMPS ==========
    
    deadline = fields.Date(
        string='Date limite',
        tracking=True,
        help="Date limite pour terminer la t√¢che"
    )
    
    estimated_hours = fields.Float(
        string='Dur√©e estim√©e (heures)',
        default=0.0,
        help="Estimation du temps n√©cessaire en heures"
    )
    
    # ========== CHAMPS RELATIONNELS ==========
    
    user_id = fields.Many2one(
        'res.users',
        string='Assign√© √†',
        default=lambda self: self.env.user,
        tracking=True,
        help="Utilisateur responsable de la t√¢che"
    )
    
    team_member_id = fields.Many2one(
        'task.manager.team.member',
        string='Membre d\'√©quipe',
        ondelete='set null',
        tracking=True,
        help="Membre d'√©quipe assign√©"
    )
    
    # ========== CHAMPS IA ==========
    
    ai_suggestions = fields.Html(
        string='Suggestions IA',
        readonly=True,
        help="Suggestions g√©n√©r√©es par l'intelligence artificielle"
    )
    
    subtasks = fields.Text(
        string='Sous-t√¢ches sugg√©r√©es',
        help="Liste des sous-t√¢ches g√©n√©r√©es par IA"
    )
    
    # Relation avec l'historique IA
    ai_history_ids = fields.One2many(
        'task.ai.history',
        'task_id',
        string='Historique IA',
        help='Historique de toutes les g√©n√©rations IA pour cette t√¢che'
    )
    
    # Compteur de g√©n√©rations
    ai_suggestion_count = fields.Integer(
        string='Nombre de suggestions IA',
        compute='_compute_ai_suggestion_count',
        store=True
    )
    
    # ========== CHAMPS CALCUL√âS ==========
    
    is_overdue = fields.Boolean(
        string='En retard',
        compute='_compute_is_overdue',
        store=True,
        help="Indique si la t√¢che est en retard"
    )
    
    # ========== CHAMPS SYST√àME ==========
    
    active = fields.Boolean(default=True)
    
    # ========== M√âTHODES DE CALCUL ==========
    
    @api.depends('deadline', 'state')
    def _compute_is_overdue(self):
        """Calcule si la t√¢che est en retard"""
        today = date.today()
        for task in self:
            if task.deadline and task.state != 'done':
                task.is_overdue = task.deadline < today
            else:
                task.is_overdue = False
    
    @api.depends('ai_history_ids')
    def _compute_ai_suggestion_count(self):
        """Compte le nombre de g√©n√©rations IA r√©ussies"""
        for task in self:
            task.ai_suggestion_count = len(task.ai_history_ids.filtered(lambda h: h.success))
    
    # ========== CONTRAINTES ==========
    
    @api.constrains('deadline')
    def _check_deadline(self):
        """V√©rifie que la deadline n'est pas dans le pass√©"""
        for task in self:
            if task.deadline and task.deadline < fields.Date.context_today(self):
                if task.state == 'new':  # Seulement pour les nouvelles t√¢ches
                    raise ValidationError("La date limite ne peut pas √™tre dans le pass√©.")
    
    # ========== M√âTHODES DE GESTION DES T√ÇCHES ==========
    
    def action_start_task(self):
        """D√©marre la t√¢che"""
        for task in self:
            if task.state == 'new':
                task.state = 'in_progress'
        return True
    
    def action_complete_task(self):
        """Termine la t√¢che"""
        for task in self:
            if task.state == 'in_progress':
                task.state = 'done'
        return True
    
    def action_reset_task(self):
        """R√©initialise la t√¢che"""
        for task in self:
            task.state = 'new'
        return True
    
    # ========== M√âTHODES IA ==========
    
    def action_generate_ai_description(self):
        """
        G√©n√®re automatiquement une description d√©taill√©e bas√©e sur le titre
        """
        self.ensure_one()
        
        if not self.name:
            raise UserError("‚ùå Impossible de g√©n√©rer une description sans titre !")
        
        # V√©rifier la configuration
        ai_config = self.env['task.ai.config']
        ai_config.check_daily_limit()
        config = ai_config.get_config()
        
        if not config['enabled']:
            raise UserError("‚ùå L'IA est d√©sactiv√©e. Activez-la dans les param√®tres.")
        
        # Pr√©parer le prompt
        prompt = f"""Tu es un assistant de gestion de projet professionnel.
Titre de la t√¢che : {self.name}

G√©n√®re une description professionnelle et d√©taill√©e de cette t√¢che qui explique :
1. L'objectif principal
2. Les √©tapes √† suivre
3. Les r√©sultats attendus

Sois concis mais complet (maximum 200 mots).
R√©ponds en fran√ßais, sans introduction ni conclusion."""
        
        start_time = time.time()
        
        try:
            # Appel √† l'API Claude
            client = anthropic.Anthropic(api_key=config['api_key'])
            
            response = client.messages.create(
                model=config['model'],
                max_tokens=config['max_tokens'],
                temperature=config['temperature'],
                messages=[{
                    "role": "user",
                    "content": prompt
                }]
            )
            
            # Extraire la r√©ponse
            description = response.content[0].text.strip()
            execution_time = time.time() - start_time
            
            # Mettre √† jour la t√¢che
            self.write({'description': description})
            
            # Logger dans l'historique
            self.env['task.ai.history'].create_log(
                task_id=self.id,
                generation_type='description',
                prompt=prompt,
                response=description,
                success=True,
                tokens=response.usage.input_tokens + response.usage.output_tokens,
                exec_time=execution_time,
                model=config['model']
            )
            
            return {
                'type': 'ir.actions.client',
                'tag': 'display_notification',
                'params': {
                    'title': '‚úÖ Description g√©n√©r√©e !',
                    'message': f'La description a √©t√© g√©n√©r√©e avec succ√®s en {execution_time:.1f}s',
                    'type': 'success',
                    'sticky': False,
                }
            }
            
        except Exception as e:
            error_msg = str(e)
            _logger.error(f"Erreur lors de la g√©n√©ration de description : {error_msg}")
            
            # Logger l'erreur
            self.env['task.ai.history'].create_log(
                task_id=self.id,
                generation_type='description',
                prompt=prompt,
                success=False,
                error=error_msg,
                exec_time=time.time() - start_time,
                model=config.get('model', '')
            )
            
            # Messages d'erreur sp√©cifiques
            if 'authentication' in error_msg.lower() or 'api_key' in error_msg.lower():
                message = "Cl√© API invalide. V√©rifiez votre configuration."
            elif 'quota' in error_msg.lower() or 'rate_limit' in error_msg.lower():
                message = "Quota API d√©pass√©. R√©essayez plus tard."
            else:
                message = f"Erreur : {error_msg}"
            
            return {
                'type': 'ir.actions.client',
                'tag': 'display_notification',
                'params': {
                    'title': '‚ùå Erreur de g√©n√©ration',
                    'message': message,
                    'type': 'danger',
                    'sticky': True,
                }
            }
    
    def action_generate_ai_subtasks(self):
        """
        G√©n√®re automatiquement des sous-t√¢ches bas√©es sur le titre et la description
        """
        self.ensure_one()
        
        if not self.name:
            raise UserError("‚ùå Impossible de g√©n√©rer des sous-t√¢ches sans titre !")
        
        # V√©rifier la configuration
        ai_config = self.env['task.ai.config']
        ai_config.check_daily_limit()
        config = ai_config.get_config()
        
        # Pr√©parer le prompt
        description_text = self.description or "Pas de description disponible"
        
        prompt = f"""Titre : {self.name}
Description : {description_text}

G√©n√®re une liste de 3 √† 5 sous-t√¢ches concr√®tes pour accomplir cette t√¢che principale.
Chaque sous-t√¢che doit √™tre :
- Actionnable
- Mesurable
- Courte (une ligne)

Format : liste √† puces en markdown.
R√©ponds en fran√ßais, sans introduction ni conclusion.
Exemple de format attendu :
- Sous-t√¢che 1
- Sous-t√¢che 2
- Sous-t√¢che 3"""
        
        start_time = time.time()
        
        try:
            client = anthropic.Anthropic(api_key=config['api_key'])
            
            response = client.messages.create(
                model=config['model'],
                max_tokens=config['max_tokens'],
                temperature=config['temperature'],
                messages=[{
                    "role": "user",
                    "content": prompt
                }]
            )
            
            subtasks = response.content[0].text.strip()
            execution_time = time.time() - start_time
            
            self.write({'subtasks': subtasks})
            
            self.env['task.ai.history'].create_log(
                task_id=self.id,
                generation_type='subtasks',
                prompt=prompt,
                response=subtasks,
                success=True,
                tokens=response.usage.input_tokens + response.usage.output_tokens,
                exec_time=execution_time,
                model=config['model']
            )
            
            return {
                'type': 'ir.actions.client',
                'tag': 'display_notification',
                'params': {
                    'title': '‚úÖ Sous-t√¢ches g√©n√©r√©es !',
                    'message': f'{len(subtasks.split(chr(10)))} sous-t√¢ches cr√©√©es en {execution_time:.1f}s',
                    'type': 'success',
                    'sticky': False,
                }
            }
            
        except Exception as e:
            error_msg = str(e)
            _logger.error(f"Erreur g√©n√©ration sous-t√¢ches : {error_msg}")
            
            self.env['task.ai.history'].create_log(
                task_id=self.id,
                generation_type='subtasks',
                prompt=prompt,
                success=False,
                error=error_msg,
                exec_time=time.time() - start_time
            )
            
            return {
                'type': 'ir.actions.client',
                'tag': 'display_notification',
                'params': {
                    'title': '‚ùå Erreur',
                    'message': f'Impossible de g√©n√©rer les sous-t√¢ches : {error_msg}',
                    'type': 'danger',
                    'sticky': True,
                }
            }
    
    def action_estimate_duration(self):
        """
        Estime automatiquement la dur√©e n√©cessaire pour accomplir la t√¢che
        """
        self.ensure_one()
        
        ai_config = self.env['task.ai.config']
        ai_config.check_daily_limit()
        config = ai_config.get_config()
        
        description_text = self.description or "Pas de description disponible"
        
        prompt = f"""Titre : {self.name}
Description : {description_text}

Estime le temps n√©cessaire pour accomplir cette t√¢che.
Donne une estimation r√©aliste en heures (nombre d√©cimal).

Consid√®re :
- La complexit√© de la t√¢che
- Les d√©pendances potentielles
- Le travail de recherche √©ventuel

R√©ponds UNIQUEMENT avec un nombre d√©cimal (exemple: 4.5)
Ne mets AUCUN texte avant ou apr√®s le nombre."""
        
        start_time = time.time()
        
        try:
            client = anthropic.Anthropic(api_key=config['api_key'])
            
            response = client.messages.create(
                model=config['model'],
                max_tokens=50,
                temperature=0.3,  # Moins cr√©atif pour les chiffres
                messages=[{
                    "role": "user",
                    "content": prompt
                }]
            )
            
            response_text = response.content[0].text.strip()
            
            # Extraire le nombre de la r√©ponse
            match = re.search(r'(\d+\.?\d*)', response_text)
            if not match:
                raise ValueError("Aucun nombre trouv√© dans la r√©ponse")
            
            estimated_hours = float(match.group(1))
            
            # Validation
            if estimated_hours <= 0 or estimated_hours > 1000:
                raise ValueError(f"Estimation invalide : {estimated_hours}h")
            
            execution_time = time.time() - start_time
            
            self.write({'estimated_hours': estimated_hours})
            
            self.env['task.ai.history'].create_log(
                task_id=self.id,
                generation_type='duration',
                prompt=prompt,
                response=response_text,
                success=True,
                tokens=response.usage.input_tokens + response.usage.output_tokens,
                exec_time=execution_time,
                model=config['model']
            )
            
            return {
                'type': 'ir.actions.client',
                'tag': 'display_notification',
                'params': {
                    'title': '‚úÖ Dur√©e estim√©e !',
                    'message': f'Estimation : {estimated_hours}h',
                    'type': 'success',
                    'sticky': False,
                }
            }
            
        except Exception as e:
            error_msg = str(e)
            _logger.error(f"Erreur estimation dur√©e : {error_msg}")
            
            self.env['task.ai.history'].create_log(
                task_id=self.id,
                generation_type='duration',
                prompt=prompt,
                success=False,
                error=error_msg,
                exec_time=time.time() - start_time
            )
            
            return {
                'type': 'ir.actions.client',
                'tag': 'display_notification',
                'params': {
                    'title': '‚ùå Erreur',
                    'message': f'Impossible d\'estimer la dur√©e : {error_msg}',
                    'type': 'danger',
                    'sticky': True,
                }
            }
    
    def action_suggest_priority(self):
        """
        Sugg√®re un niveau de priorit√© bas√© sur le contexte de la t√¢che
        """
        self.ensure_one()
        
        ai_config = self.env['task.ai.config']
        ai_config.check_daily_limit()
        config = ai_config.get_config()
        
        description_text = self.description or "Pas de description disponible"
        deadline_text = str(self.deadline) if self.deadline else "non d√©finie"
        
        prompt = f"""Titre : {self.name}
Description : {description_text}
Deadline : {deadline_text}

Analyse cette t√¢che et sugg√®re un niveau de priorit√©.

Crit√®res :
- high : urgent, critique, deadline proche, bloquant
- medium : important mais pas urgent, deadline raisonnable
- low : peut attendre, nice to have, pas de deadline proche

R√©ponds UNIQUEMENT avec : low, medium, ou high
Ne mets AUCUN autre texte."""
        
        start_time = time.time()
        
        try:
            client = anthropic.Anthropic(api_key=config['api_key'])
            
            response = client.messages.create(
                model=config['model'],
                max_tokens=20,
                temperature=0.3,
                messages=[{
                    "role": "user",
                    "content": prompt
                }]
            )
            
            suggested_priority = response.content[0].text.strip().lower()
            
            # Validation
            if suggested_priority not in ['low', 'medium', 'high']:
                raise ValueError(f"Priorit√© invalide : {suggested_priority}")
            
            execution_time = time.time() - start_time
            
            self.env['task.ai.history'].create_log(
                task_id=self.id,
                generation_type='priority',
                prompt=prompt,
                response=suggested_priority,
                success=True,
                tokens=response.usage.input_tokens + response.usage.output_tokens,
                exec_time=execution_time,
                model=config['model']
            )
            
            # Cr√©er un wizard pour demander confirmation
            wizard = self.env['task.priority.wizard'].create({
                'task_id': self.id,
                'suggested_priority': suggested_priority,
            })
            
            return {
                'name': 'Suggestion de Priorit√©',
                'type': 'ir.actions.act_window',
                'res_model': 'task.priority.wizard',
                'view_mode': 'form',
                'res_id': wizard.id,
                'target': 'new',
            }
            
        except Exception as e:
            error_msg = str(e)
            _logger.error(f"Erreur suggestion priorit√© : {error_msg}")
            
            self.env['task.ai.history'].create_log(
                task_id=self.id,
                generation_type='priority',
                prompt=prompt,
                success=False,
                error=error_msg,
                exec_time=time.time() - start_time
            )
            
            return {
                'type': 'ir.actions.client',
                'tag': 'display_notification',
                'params': {
                    'title': '‚ùå Erreur',
                    'message': f'Impossible de sugg√©rer la priorit√© : {error_msg}',
                    'type': 'danger',
                    'sticky': True,
                }
            }
    
    def action_generate_all_ai_suggestions(self):
        """
        G√©n√®re toutes les suggestions IA en une seule fois
        """
        self.ensure_one()
        
        if not self.name:
            raise UserError("‚ùå Impossible de g√©n√©rer des suggestions sans titre !")
        
        results = []
        
        try:
            # 1. Description
            result = self.action_generate_ai_description()
            if result.get('params', {}).get('type') == 'success':
                results.append('‚úÖ Description')
            else:
                results.append('‚ùå Description')
            
            # 2. Sous-t√¢ches
            result = self.action_generate_ai_subtasks()
            if result.get('params', {}).get('type') == 'success':
                results.append('‚úÖ Sous-t√¢ches')
            else:
                results.append('‚ùå Sous-t√¢ches')
            
            # 3. Dur√©e
            result = self.action_estimate_duration()
            if result.get('params', {}).get('type') == 'success':
                results.append('‚úÖ Dur√©e')
            else:
                results.append('‚ùå Dur√©e')
            
            # 4. Priorit√©
            result = self.action_suggest_priority()
            results.append('‚úÖ Priorit√© (√† confirmer)')
            
            summary = '\n'.join(results)
            
            return {
                'type': 'ir.actions.client',
                'tag': 'display_notification',
                'params': {
                    'title': 'üéâ G√©n√©ration compl√®te termin√©e !',
                    'message': f'R√©sultats :\n{summary}',
                    'type': 'success',
                    'sticky': True,
                }
            }
            
        except Exception as e:
            _logger.error(f"Erreur g√©n√©ration compl√®te : {str(e)}")
            return {
                'type': 'ir.actions.client',
                'tag': 'display_notification',
                'params': {
                    'title': '‚ùå Erreur',
                    'message': f'G√©n√©ration interrompue : {str(e)}',
                    'type': 'danger',
                    'sticky': True,
                }
            }